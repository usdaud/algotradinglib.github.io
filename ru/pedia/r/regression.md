# Регрессия в финансах и торговле

Регрессионный анализ — это статистический инструмент, который исследует взаимосвязь между двумя или более переменными. Он широко используется в сферах финансов и торговли для моделирования и анализа взаимосвязей между различными ценами активов или экономическими индикаторами. Его основная цель — понять, как изменяется зависимая переменная при изменении какой-либо одной из независимых переменных, в то время как другие независимые переменные остаются фиксированными.

## Типы регрессии

### 1. Простая линейная регрессия

Простая линейная регрессия включает единственную переменную-предиктор и обычно используется, когда существует прямолинейная взаимосвязь между независимой переменной \(X\) и зависимой переменной \(Y\). Взаимосвязь может быть описана как:

\[ Y = \beta_0 + \beta_1X + \epsilon \]

Где:

- \(Y\) — зависимая переменная.
- \(X\) — независимая переменная.
- \(\beta_0\) — пересечение по оси y.
- \(\beta_1\) — наклон линии.
- \(\epsilon\) — случайный член ошибки.

#### Пример в торговле

Предположим, вы хотите предсказать будущие цены акции на основе ее исторических цен. Историческая цена — ваша независимая переменная \(X\), а будущая цена — ваша зависимая переменная \(Y\).

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm

# Создание dataframe с историческими ценами
data = pd.DataFrame{
    'Historical_Price': [100, 101, 102, 103, 104],
    'Future_Price': [101, 102, 103, 104, 105]
})

# Подгонка модели
X = data['Historical_Price']
y = data['Future_Price']
X = sm.add_constant(X)  # Добавляет константный член к предиктору
model = sm.OLS(y, X).fit()

# Прогнозы
predictions = model.predict(X)
print(predictions)
```

### 2. Множественная линейная регрессия

Множественная линейная регрессия включает две или более переменных-предикторов. Взаимосвязь может быть описана как:

\[ Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \ldots + \beta_pX_p + \epsilon \]

Где:

- \(X_1, X_2, \ldots, X_p\) — переменные-предикторы.

#### Пример в торговле

Прогнозирование будущих цен акции на основе нескольких факторов, таких как исторические цены, объем и рыночные индексы.

```python
# Создание dataframe с несколькими факторами
data = pd.DataFrame{
    'Historical_Price': [100, 101, 102, 103, 104],
    'Volume': [2000, 2200, 2100, 2300, 2400],
    'Market_Index': [1500, 1520, 1510, 1530, 1540],
    'Future_Price': [101, 102, 103, 104, 105]
})

# Подгонка модели
X = data[['Historical_Price', 'Volume', 'Market_Index']]
y = data['Future_Price']
X = sm.add_constant(X)  # Добавляет константный член к предиктору
model = sm.OLS(y, X).fit()

# Прогнозы
predictions = model.predict(X)
print(predictions)
```

### 3. Полиномиальная регрессия

Когда взаимосвязь между независимой переменной и зависимой переменной нелинейна, можно использовать полиномиальную регрессию. Взаимосвязь может быть описана как:

\[ Y = \beta_0 + \beta_1X + \beta_2X^2 + \beta_3X^3 + \ldots + \beta_dX^d + \epsilon \]

Где:

- \(d\) — степень полинома.

#### Пример в торговле

Прогнозирование будущих цен акции, где цена может иметь квадратичную или кубическую взаимосвязь с независимыми переменными.

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# Создание dataframe
data = pd.DataFrame{
    'Historical_Price': [100, 101, 102, 103, 104],
    'Future_Price': [101, 102, 103, 104, 105]
})

# Подготовка полиномиальных признаков
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(data[['Historical_Price']])

# Подгонка модели
lin_reg = LinearRegression()
lin_reg.fit(X_poly, data['Future_Price'])

# Прогнозы
predictions = lin_reg.predict(X_poly)
print(predictions)
```

## Методы оценки точности модели

### 1. R-квадрат

R-квадрат — это статистическая мера, которая представляет долю дисперсии зависимой переменной, которая объясняется независимой переменной (переменными).

\[ R^2 = 1 - \frac{SS_{res}}{SS_{tot}} \]

Где:

- \(SS_{res}\) — сумма квадратов остатков.
- \(SS_{tot}\) — общая сумма квадратов.

### 2. Скорректированный R-квадрат

Скорректированный R-квадрат корректирует значение R-квадрат на основе количества предикторов в модели. Он полезен при сравнении моделей с разным количеством предикторов.

\[ \text{Скорректированный } R^2 = 1 - \frac{(1-R^2)(n-1)}{n-k-1} \]

Где:

- \(n\) — количество наблюдений.
- \(k\) — количество предикторов.

### 3. Среднеквадратическая ошибка (MSE)

Среднеквадратическая ошибка — это среднее значение квадратов ошибок. Ошибка — это величина, на которую наблюдаемое значение отличается от прогнозируемого значения.

\[ MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2 \]

Где:

- \(n\) — количество наблюдений.
- \(y_i\) — наблюдаемое значение.
- \(\hat{y_i}\) — прогнозируемое значение.

## Методы регуляризации

### 1. Ридж-регрессия

Ридж-регрессия использует L2-регуляризацию для сжатия коэффициентов модели, что помогает предотвратить переобучение. Целевая функция:

\[ \min_{\beta} \| y - X\beta \|^2_2 + \lambda \| \beta \|^2_2 \]

Где:

- \(\lambda\) — параметр регуляризации.

### 2. Лассо-регрессия

Лассо-регрессия использует L1-регуляризацию для наложения ограничения, при котором некоторые коэффициенты точно равны нулю, тем самым обеспечивая выбор признаков. Целевая функция:

\[ \min_{\beta} \| y - X\beta \|^2_2 + \lambda \| \beta \|_1 \]

### Пример ридж и лассо регрессии

```python
from sklearn.linear_model import Ridge, Lasso

# Генерация набора данных
data = pd.DataFrame{
    'Historical_Price': [100, 101, 102, 103, 104],
    'Volume': [2000, 2200, 2100, 2300, 2400],
    'Market_Index': [1500, 1520, 1510, 1530, 1540],
    'Future_Price': [101, 102, 103, 104, 105]
})

# Ридж-регрессия
ridge = Ridge(alpha=1.0)
ridge.fit(data[['Historical_Price', 'Volume', 'Market_Index']], data['Future_Price'])
ridge_predictions = ridge.predict(data[['Historical_Price', 'Volume', 'Market_Index']])
print('Прогнозы Ridge:', ridge_predictions)

# Лассо-регрессия
lasso = Lasso(alpha=0.1)
lasso.fit(data[['Historical_Price', 'Volume', 'Market_Index']], data['Future_Price'])
lasso_predictions = lasso.predict(data[['Historical_Price', 'Volume', 'Market_Index']])
print('Прогнозы Lasso:', lasso_predictions)
```

## Применение регрессии в финансах

### 1. Управление рисками

Регрессия широко используется в управлении рисками для моделирования взаимосвязи между доходностью портфеля и рыночными факторами. Например, модель оценки капитальных активов (CAPM) — это модель линейной регрессии, которая описывает взаимосвязь между ожидаемой доходностью акции и ее риском по сравнению с рынком.

### 2. Оценка стоимости

При оценке стоимости регрессионный анализ может помочь оценить стоимость компании путем анализа взаимосвязей между финансовыми показателями компании (такими как прибыль, выручка и денежный поток) и ее рыночной стоимостью.

### 3. Алгоритмическая торговля

В алгоритмической торговле модели регрессии используются для прогнозирования будущих ценовых движений на основе исторических данных. Коэффициенты модели регрессии могут помочь определить, насколько сильно различные факторы влияют на цену актива.

## Компании, использующие регрессию в финансах

### 1. JPMorgan Chase

JPMorgan Chase использует продвинутые статистические модели, включая регрессионный анализ, для управления рисками, оптимизации портфеля и алгоритмической торговли.

### 2. Goldman Sachs

Goldman Sachs использует модели регрессии для анализа рыночных трендов, прогнозирования экономических условий и разработки торговых стратегий.

### 3. QuantConnect

QuantConnect — это платформа, которая предлагает инструменты для разработки стратегий алгоритмической торговли, часто включающих модели на основе регрессии в свой аналитический набор.

## Заключение

Регрессионный анализ — это мощный инструмент в финансах и торговле, предоставляющий ценные идеи и помогающий моделировать сложные взаимосвязи между переменными. Будь то управление рисками, оценка стоимости или алгоритмическая торговля, понимание и применение принципов регрессии может значительно улучшить процессы принятия решений. По мере роста сложности финансовых рынков будет расти и важность и изощренность моделей на основе регрессии.
