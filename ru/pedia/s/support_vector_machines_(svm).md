# Машины опорных векторов (SVM)

Машины опорных векторов (SVM) - это набор методов обучения с учителем, используемых для классификации, регрессии и обнаружения выбросов. Первоначально разработанные для задач бинарной классификации, SVM - это мощные универсальные алгоритмы, хорошо подходящие для широкого спектра задач.

## Основы SVM

### Основная идея

Фундаментальная идея, лежащая в основе SVM, состоит в том, чтобы найти лучшую разделяющую гиперплоскость, которая делит набор данных на классы. В 2D пространстве это аналогично проведению линии, которая лучше всего разделяет точки данных по разным классам. Цель состоит в максимизации маржи, то есть расстояния между гиперплоскостью и ближайшей точкой данных из любого класса. Эта гиперплоскость называется оптимальной гиперплоскостью.

### Математическая формулировка

Дан набор учебных точек данных следующего вида:
\[ (x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n) \]
Где \( x_i \) - вектор, представляющий входные признаки, и \( y_i \) - метка класса.

Алгоритм SVM находит гиперплоскость, определяемую как:
\[ w \cdot x - b = 0 \]
Где \( w \) - вектор веса, \( x \) - вектор входа, и \( b \) - член смещения.

Цель состоит в максимизации маржи, которая задается как:
\[ \text{Margin} = \frac{2}{||w||} \]
Это приводит к задаче квадратичной оптимизации с ограничениями:
\[ \text{minimize} \quad \frac{1}{2} ||w||^2 \]
При условии:
\[ y_i (w \cdot x_i - b) \geq 1 \]

### Опорные векторы

Точки данных, которые находятся ближе всего к гиперплоскости, называются опорными векторами. Эти точки критически важны, так как они определяют положение и ориентацию гиперплоскости. Если точка находится вне маржи, она не является опорным вектором и не влияет на модель.

## Типы SVM

### Линейный SVM

Линейный SVM хорошо работает, когда данные линейно разделимы, что означает, что одна линия может разделять классы в 2D пространстве или гиперплоскость может разделять их в пространстве более высокой размерности. Цель состоит в том, чтобы найти эту оптимальную гиперплоскость.

### Нелинейный SVM

Когда данные не являются линейно разделимыми, SVM все еще можно использовать благодаря применению трюка ядра. Функция ядра трансформирует входное пространство в пространство более высокой размерности, где гиперплоскость может эффективно разделять классы.

#### Общие функции ядра

1. **Полиномиальное ядро:**
\[ K(x_i, x_j) = (x_i \cdot x_j + c)^d \]
2. **Ядро радиальной базисной функции (RBF) / гауссовское ядро:**
\[ K(x_i, x_j) = \exp(-\gamma ||x_i - x_j||^2) \]
3. **Сигмовидное ядро:**
\[ K(x_i, x_j) = \tanh(\alpha x_i \cdot x_j + c) \]

### SVM для регрессии (SVR)

Регрессия опорных векторов (SVR) - это расширение SVM для задач регрессии. SVR стремится найти функцию, которая отклоняется от фактических наблюдаемых целей на значение не больше, чем указанная маржа. Цель состоит в том, чтобы гарантировать, что прогнозируемое значение находится в пределах определенного расстояния от фактического значения, определяемого параметром порога \( \epsilon \).

#### Формулировка

SVR пытается минимизировать следующую функцию потерь:
\[ \frac{1}{2} ||w||^2 + C \sum_{i=1}^n L_{\epsilon}(y_i, f(x_i)) \]

Где \( L_{\epsilon} \) - функция потерь, нечувствительная к эпсилону:
\[ L_{\epsilon}(y, f(x)) = \max(0, |y - f(x)| - \epsilon) \]

### SVM для обнаружения выбросов

One-Class SVM, расширение SVM, особенно полезно для обнаружения выбросов и обнаружения аномалий. Он подгоняет модель SVM к "нормальным" данным и идентифицирует выбросы, которые выходят за пределы изученной границы решения.

## Реализация SVM

### Библиотеки и инструменты

1. **scikit-learn:** Популярная библиотека Python для машинного обучения, которая обеспечивает надежную поддержку SVM через свой модуль `svm`. scikit-learn
2. **LIBSVM:** Библиотека для машин опорных векторов, которая широко используется для реализации SVM. LIBSVM
3. **TensorFlow:** Библиотека машинного обучения с открытым исходным кодом, которая также поддерживает реализацию SVM. TensorFlow SVM
4. **KERAS:** Библиотека программного обеспечения с открытым исходным кодом, которая обеспечивает интерфейс Python для искусственных нейронных сетей и также имеет модули для интеграции SVM. KERAS

### Пример кода на Python

Вот простой пример реализации линейного SVM с использованием `scikit-learn`:

```python
from sklearn import svm
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# Создать случайный набор данных
X, y = make_classification(n_samples=100, n_features=2, n_classes=2, random_state=42)

# Разделить набор данных на наборы для обучения и тестирования
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Создать классификатор линейный SVM
clf = svm.SVC(kernel='linear')

# Обучить классификатор
clf.fit(X_train, y_train)

# Сделать прогнозы
y_pred = clf.predict(X_test)

print("Predictions: ", y_pred)
print("Accuracy: ", clf.score(X_test, y_test))
```

## Применение SVM

### Прогноз финансового рынка

SVM широко используются в финансовой индустрии для прогнозирования цен акций, управления рисками и алгоритмической торговле. Они могут моделировать сложные связи в финансовых данных и обеспечивать надежные прогностические возможности.

### Медицинская диагностика

В медицинской диагностике SVM помогают в классификации заболеваний на основе симптомов или результатов тестов. Например, SVM могут отличить раковые клетки от нераковых.

### Биоинформатика

Биоинформатика включает большие наборы данных, такие как данные об экспрессии генов. SVM могут эффективно классифицировать и анализировать эти данные для определения функций генов и взаимодействий.

### Распознавание изображений и речи

SVM широко используются в системах распознавания изображений и речи. Они помогают в распознавании почерка, обнаружении лиц и классификации голоса.

### Категоризация текста

Машины опорных векторов могут эффективно категоризировать текст, такой как электронные письма, новостные статьи и сообщения в социальных сетях, по предопределенным категориям. Они полезны при обнаружении спама, анализе тональности и классификации тем.

## Проблемы с SVM

1. **Высокие вычислительные затраты:** Обучение SVM на больших наборах данных может быть трудоемким и требовать значительных вычислительных ресурсов.
2. **Выбор ядра:** Выбор подходящей функции ядра и настройка ее параметров критически важны и могут быть сложными.
3. **Чувствительность к выбору параметров:** Производительность SVM чувствительна к выбору параметров, таких как C (регуляризация) и γ (гамма в RBF ядре).

## Резюме

Машины опорных векторов - это мощные универсальные алгоритмы машинного обучения, способные справляться с задачами классификации, регрессии и обнаружения выбросов. Они особенно хорошо подходят для сложных многомерных наборов данных. Несмотря на их вычислительную сложность и чувствительность к настройке параметров, их способность находить оптимальные гиперплоскости и их мастерство с методами ядра делают их необходимым инструментом в арсенале специалиста по обработке данных.
